#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Ø³ÛŒØ³ØªÙ… Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ùˆ ØªØ­Ù„ÛŒÙ„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø±ÙˆØ²Ø§Ù†Ù‡ Ø¨Ø§ Ø§Ù†ØªÙ‚Ø§Ù„ Ø´Ø¨Ø§Ù†Ù‡ Ø¨Ù‡ MongoDB
"""

import os
import json
import sqlite3
from datetime import datetime, time, timedelta
import schedule
import threading
import logging
import time as time_module
from typing import Dict, List, Any
import numpy as np
from openai import OpenAI
from monitoring.persian_reporter import PersianReporter, SystemComponent, ReportLevel

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class DailyDataCollectionSystem:
    def __init__(self):
        self.temp_db = 'temp_daily_data.db'
        self.analysis_db = 'daily_analysis.db'
        self.mongodb_queue = 'mongodb_queue.json'
        
        # Ø³Ø§Ø¹Øª Ø§Ù†ØªÙ‚Ø§Ù„ Ø¨Ù‡ MongoDB (23:30)
        self.transfer_time = time(23, 30)
        
        # Ø§Ù…ØªÛŒØ§Ø²Ø¯Ù‡ÛŒ Ùˆ ÙˆØ²Ù†â€ŒÙ‡Ø§
        self.scoring_weights = {
            'price_movement': 0.25,
            'volume': 0.20,
            'news_sentiment': 0.20,
            'technical_indicators': 0.15,
            'ai_prediction': 0.20
        }
        
        # Ù…Ù‚Ø¯Ø§Ø±Ø¯Ù‡ÛŒ Ø§ÙˆÙ„ÛŒÙ‡
        self._initialize_databases()
        self.openai_client = OpenAI() if os.environ.get('OPENAI_API_KEY') else None
        
        # Ø§ÛŒØ¬Ø§Ø¯ Ú¯Ø²Ø§Ø±Ø´Ú¯Ø± ÙØ§Ø±Ø³ÛŒ
        self.reporter = PersianReporter(
            SystemComponent.DATA_COLLECTION,
            log_file="monitoring/logs/data_collection_fa.log"
        )
        
        self.reporter.success(
            "Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø³ÛŒØ³ØªÙ…",
            "Ø³ÛŒØ³ØªÙ… Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø±ÙˆØ²Ø§Ù†Ù‡ Ø¨Ø§ Ú¯Ø²Ø§Ø±Ø´Ø¯Ù‡ÛŒ ÙØ§Ø±Ø³ÛŒ Ø¢Ù…Ø§Ø¯Ù‡ Ø´Ø¯"
        )
    
    def _initialize_databases(self):
        """Ø§ÛŒØ¬Ø§Ø¯ Ø¬Ø¯Ø§ÙˆÙ„ Ù…ÙˆÙ‚Øª Ø¨Ø±Ø§ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø±ÙˆØ²Ø§Ù†Ù‡"""
        # Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Ù…ÙˆÙ‚Øª Ø±ÙˆØ²Ø§Ù†Ù‡
        conn = sqlite3.connect(self.temp_db)
        cursor = conn.cursor()
        
        # Ø¬Ø¯ÙˆÙ„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø®Ø§Ù…
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS raw_data (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                timestamp TEXT,
                data_type TEXT,
                market TEXT,
                symbol TEXT,
                data JSON,
                processed BOOLEAN DEFAULT 0
            )
        ''')
        
        # Ø¬Ø¯ÙˆÙ„ ØªØ­Ù„ÛŒÙ„â€ŒÙ‡Ø§
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS analysis_results (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                timestamp TEXT,
                symbol TEXT,
                analysis_type TEXT,
                score REAL,
                details JSON
            )
        ''')
        
        conn.commit()
        conn.close()
        
        # Ø¯ÛŒØªØ§Ø¨ÛŒØ³ ØªØ­Ù„ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù†Ù‡Ø§ÛŒÛŒ
        conn = sqlite3.connect(self.analysis_db)
        cursor = conn.cursor()
        
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS daily_summaries (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                date TEXT,
                symbol TEXT,
                final_score REAL,
                recommendation TEXT,
                analysis JSON,
                transferred_to_mongodb BOOLEAN DEFAULT 0
            )
        ''')
        
        conn.commit()
        conn.close()
        
        self.reporter.info(
            "Ù…Ù‚Ø¯Ø§Ø±Ø¯Ù‡ÛŒ Ù¾Ø§ÛŒÚ¯Ø§Ù‡ Ø¯Ø§Ø¯Ù‡",
            "Ø¬Ø¯Ø§ÙˆÙ„ Ù¾Ø§ÛŒÚ¯Ø§Ù‡ Ø¯Ø§Ø¯Ù‡ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯Ù†Ø¯"
        )
    
    def collect_market_data(self, symbol: str, market: str) -> Dict:
        """Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¨Ø§Ø²Ø§Ø±"""
        data = {
            'timestamp': datetime.now().isoformat(),
            'symbol': symbol,
            'market': market,
            'price': np.random.uniform(100, 50000),  # Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ Ù‚ÛŒÙ…Øª
            'volume': np.random.uniform(1000, 100000),
            'change_24h': np.random.uniform(-10, 10),
            'high_24h': np.random.uniform(100, 51000),
            'low_24h': np.random.uniform(99, 49000)
        }
        
        # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Ù…ÙˆÙ‚Øª
        conn = sqlite3.connect(self.temp_db)
        cursor = conn.cursor()
        
        cursor.execute('''
            INSERT INTO raw_data (timestamp, data_type, market, symbol, data)
            VALUES (?, ?, ?, ?, ?)
        ''', (
            data['timestamp'],
            'market_data',
            market,
            symbol,
            json.dumps(data)
        ))
        
        conn.commit()
        conn.close()
        
        self.reporter.success(
            "Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø¯Ø§Ø¯Ù‡",
            f"Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¨Ø§Ø²Ø§Ø± {symbol} Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø´Ø¯ - Ù‚ÛŒÙ…Øª: ${data['price']:.2f}",
            {
                'symbol': symbol,
                'market': market,
                'price': data['price'],
                'volume': data['volume'],
                'change_24h': data['change_24h']
            }
        )
        
        logger.info(f"ğŸ“Š Ø¯Ø§Ø¯Ù‡ Ø¨Ø§Ø²Ø§Ø± Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø´Ø¯: {symbol} - Ù‚ÛŒÙ…Øª: ${data['price']:.2f}")
        return data
    
    def analyze_and_score(self, symbol: str) -> Dict:
        """ØªØ­Ù„ÛŒÙ„ Ùˆ Ø§Ù…ØªÛŒØ§Ø²Ø¯Ù‡ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§"""
        conn = sqlite3.connect(self.temp_db)
        cursor = conn.cursor()
        
        # Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø®Ø§Ù… Ø§Ù…Ø±ÙˆØ²
        cursor.execute('''
            SELECT data FROM raw_data 
            WHERE symbol = ? AND DATE(timestamp) = DATE('now')
            AND processed = 0
        ''', (symbol,))
        
        raw_data = cursor.fetchall()
        
        if not raw_data:
            return {}
        
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ù…ØªÛŒØ§Ø²Ø§Øª
        scores = {
            'price_movement': self._calculate_price_score(raw_data),
            'volume': self._calculate_volume_score(raw_data),
            'news_sentiment': self._calculate_news_sentiment(symbol),
            'technical_indicators': self._calculate_technical_score(raw_data),
            'ai_prediction': self._get_ai_prediction_score(symbol, raw_data)
        }
        
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ù…ØªÛŒØ§Ø² Ù†Ù‡Ø§ÛŒÛŒ
        final_score = sum(
            scores[key] * self.scoring_weights[key] 
            for key in scores
        )
        
        # ØªØ¹ÛŒÛŒÙ† ØªÙˆØµÛŒÙ‡
        if final_score >= 80:
            recommendation = "Ø®Ø±ÛŒØ¯ Ù‚ÙˆÛŒ"
        elif final_score >= 65:
            recommendation = "Ø®Ø±ÛŒØ¯"
        elif final_score >= 50:
            recommendation = "Ù†Ú¯Ù‡Ø¯Ø§Ø±ÛŒ"
        elif final_score >= 35:
            recommendation = "ÙØ±ÙˆØ´"
        else:
            recommendation = "ÙØ±ÙˆØ´ Ù‚ÙˆÛŒ"
        
        analysis_result = {
            'symbol': symbol,
            'timestamp': datetime.now().isoformat(),
            'scores': scores,
            'final_score': final_score,
            'recommendation': recommendation,
            'data_points_analyzed': len(raw_data)
        }
        
        # Ø°Ø®ÛŒØ±Ù‡ Ù†ØªÛŒØ¬Ù‡ ØªØ­Ù„ÛŒÙ„
        cursor.execute('''
            INSERT INTO analysis_results (timestamp, symbol, analysis_type, score, details)
            VALUES (?, ?, ?, ?, ?)
        ''', (
            analysis_result['timestamp'],
            symbol,
            'comprehensive',
            final_score,
            json.dumps(analysis_result)
        ))
        
        # Ø¹Ù„Ø§Ù…Øªâ€ŒÚ¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø´Ø¯Ù‡
        cursor.execute('''
            UPDATE raw_data SET processed = 1 
            WHERE symbol = ? AND DATE(timestamp) = DATE('now')
        ''', (symbol,))
        
        conn.commit()
        conn.close()
        
        self.reporter.success(
            "ØªØ­Ù„ÛŒÙ„ Ú©Ø§Ù…Ù„",
            f"ØªØ­Ù„ÛŒÙ„ {symbol} Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯ - Ø§Ù…ØªÛŒØ§Ø²: {final_score:.1f} - ØªÙˆØµÛŒÙ‡: {recommendation}",
            {
                'symbol': symbol,
                'final_score': final_score,
                'recommendation': recommendation,
                'detailed_scores': scores,
                'data_points': len(raw_data)
            }
        )
        
        logger.info(f"âœ… ØªØ­Ù„ÛŒÙ„ {symbol}: Ø§Ù…ØªÛŒØ§Ø² {final_score:.1f} - {recommendation}")
        return analysis_result
    
    def _calculate_price_score(self, raw_data: List) -> float:
        """Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ù…ØªÛŒØ§Ø² Ø­Ø±Ú©Øª Ù‚ÛŒÙ…Øª"""
        prices = []
        for row in raw_data:
            data = json.loads(row[0])
            prices.append(data['price'])
        
        if len(prices) < 2:
            return 50
        
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø±ÙˆÙ†Ø¯
        price_change = (prices[-1] - prices[0]) / prices[0] * 100
        
        # Ø§Ù…ØªÛŒØ§Ø²Ø¯Ù‡ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø±ÙˆÙ†Ø¯
        if price_change > 5:
            return 90
        elif price_change > 2:
            return 75
        elif price_change > -2:
            return 50
        elif price_change > -5:
            return 25
        else:
            return 10
    
    def _calculate_volume_score(self, raw_data: List) -> float:
        """Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ù…ØªÛŒØ§Ø² Ø­Ø¬Ù… Ù…Ø¹Ø§Ù…Ù„Ø§Øª"""
        volumes = []
        for row in raw_data:
            data = json.loads(row[0])
            volumes.append(data['volume'])
        
        if not volumes:
            return 50
        
        # Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø­Ø¬Ù…
        avg_volume = np.mean(volumes)
        recent_volume = volumes[-1] if volumes else 0
        
        # Ø§Ù…ØªÛŒØ§Ø²Ø¯Ù‡ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø­Ø¬Ù…
        volume_ratio = recent_volume / avg_volume if avg_volume > 0 else 1
        
        if volume_ratio > 2:
            return 95
        elif volume_ratio > 1.5:
            return 80
        elif volume_ratio > 1:
            return 60
        elif volume_ratio > 0.7:
            return 40
        else:
            return 20
    
    def _calculate_news_sentiment(self, symbol: str) -> float:
        """Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ø­Ø³Ø§Ø³Ø§Øª Ø®Ø¨Ø±ÛŒ"""
        # Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ Ø§Ø­Ø³Ø§Ø³Ø§Øª Ø®Ø¨Ø±ÛŒ
        # Ø¯Ø± Ø­Ø§Ù„Øª ÙˆØ§Ù‚Ø¹ÛŒ Ø§Ø² NewsAPI Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯
        return np.random.uniform(30, 80)
    
    def _calculate_technical_score(self, raw_data: List) -> float:
        """Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ù…ØªÛŒØ§Ø² Ø§Ù†Ø¯ÛŒÚ©Ø§ØªÙˆØ±Ù‡Ø§ÛŒ ØªÚ©Ù†ÛŒÚ©Ø§Ù„"""
        if not raw_data:
            return 50
        
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ RSI, MACD, etc.
        # ÙØ¹Ù„Ø§Ù‹ Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ
        return np.random.uniform(40, 85)
    
    def _get_ai_prediction_score(self, symbol: str, raw_data: List) -> float:
        """Ø¯Ø±ÛŒØ§ÙØª Ø§Ù…ØªÛŒØ§Ø² Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ AI"""
        if not self.openai_client or not raw_data:
            return 50
        
        try:
            # Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ AI
            recent_data = json.loads(raw_data[-1][0]) if raw_data else {}
            
            prompt = f"""
            Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø²ÛŒØ± Ø¨Ø±Ø§ÛŒ {symbol}ØŒ ÛŒÚ© Ø§Ù…ØªÛŒØ§Ø² Ø§Ø² 0 ØªØ§ 100 Ø¨Ø±Ø§ÛŒ Ø§Ø­ØªÙ…Ø§Ù„ Ø±Ø´Ø¯ Ù‚ÛŒÙ…Øª Ø¨Ø¯Ù‡:
            - Ù‚ÛŒÙ…Øª ÙØ¹Ù„ÛŒ: ${recent_data.get('price', 0):.2f}
            - ØªØºÛŒÛŒØ± 24 Ø³Ø§Ø¹ØªÙ‡: {recent_data.get('change_24h', 0):.2f}%
            - Ø­Ø¬Ù… Ù…Ø¹Ø§Ù…Ù„Ø§Øª: {recent_data.get('volume', 0):.0f}
            
            ÙÙ‚Ø· Ø¹Ø¯Ø¯ Ø±Ø§ Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†.
            """
            
            response = self.openai_client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[{"role": "user", "content": prompt}],
                max_tokens=10
            )
            
            score = float(response.choices[0].message.content.strip())
            return min(max(score, 0), 100)
        except:
            return 50
    
    def prepare_daily_summary(self):
        """Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø®Ù„Ø§ØµÙ‡ Ø±ÙˆØ²Ø§Ù†Ù‡ Ø¨Ø±Ø§ÛŒ Ø§Ù†ØªÙ‚Ø§Ù„ Ø¨Ù‡ MongoDB"""
        conn_temp = sqlite3.connect(self.temp_db)
        conn_analysis = sqlite3.connect(self.analysis_db)
        
        cursor_temp = conn_temp.cursor()
        cursor_analysis = conn_analysis.cursor()
        
        # Ø¯Ø±ÛŒØ§ÙØª ØªÙ…Ø§Ù… ØªØ­Ù„ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø§Ù…Ø±ÙˆØ²
        cursor_temp.execute('''
            SELECT DISTINCT symbol FROM analysis_results
            WHERE DATE(timestamp) = DATE('now')
        ''')
        
        symbols = cursor_temp.fetchall()
        
        for (symbol,) in symbols:
            # Ø¯Ø±ÛŒØ§ÙØª Ø¢Ø®Ø±ÛŒÙ† ØªØ­Ù„ÛŒÙ„ Ù‡Ø± Ø³Ù…Ø¨Ù„
            cursor_temp.execute('''
                SELECT score, details FROM analysis_results
                WHERE symbol = ? AND DATE(timestamp) = DATE('now')
                ORDER BY timestamp DESC LIMIT 1
            ''', (symbol,))
            
            result = cursor_temp.fetchone()
            if result:
                score, details = result
                
                # Ø°Ø®ÛŒØ±Ù‡ Ø®Ù„Ø§ØµÙ‡ Ø±ÙˆØ²Ø§Ù†Ù‡
                cursor_analysis.execute('''
                    INSERT INTO daily_summaries (date, symbol, final_score, recommendation, analysis)
                    VALUES (?, ?, ?, ?, ?)
                ''', (
                    datetime.now().date().isoformat(),
                    symbol,
                    score,
                    json.loads(details).get('recommendation', ''),
                    details
                ))
        
        conn_analysis.commit()
        conn_temp.close()
        conn_analysis.close()
        
        logger.info("ğŸ“‹ Ø®Ù„Ø§ØµÙ‡ Ø±ÙˆØ²Ø§Ù†Ù‡ Ø¢Ù…Ø§Ø¯Ù‡ Ø´Ø¯")
    
    def transfer_to_mongodb(self):
        """Ø§Ù†ØªÙ‚Ø§Ù„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ù‡ MongoDB Ø¯Ø± Ù¾Ø§ÛŒØ§Ù† Ø´Ø¨"""
        logger.info("ğŸŒ™ Ø´Ø±ÙˆØ¹ Ø§Ù†ØªÙ‚Ø§Ù„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ù‡ MongoDB...")
        
        # Ø¨Ø±Ø±Ø³ÛŒ Ø§ØªØµØ§Ù„ MongoDB
        mongodb_uri = os.environ.get('MONGODB_URI')
        if not mongodb_uri:
            logger.warning("âš ï¸ MongoDB URI ØªÙ†Ø¸ÛŒÙ… Ù†Ø´Ø¯Ù‡ - Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± ØµÙ")
            self._save_to_queue()
            return
        
        try:
            from pymongo import MongoClient
            client = MongoClient(mongodb_uri, serverSelectionTimeoutMS=5000)
            db = client['ultra_plus_bot']
            
            # Ø§Ù†ØªÙ‚Ø§Ù„ Ø®Ù„Ø§ØµÙ‡â€ŒÙ‡Ø§ÛŒ Ø±ÙˆØ²Ø§Ù†Ù‡
            conn = sqlite3.connect(self.analysis_db)
            cursor = conn.cursor()
            
            cursor.execute('''
                SELECT * FROM daily_summaries
                WHERE transferred_to_mongodb = 0
            ''')
            
            summaries = cursor.fetchall()
            
            if summaries:
                # ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ ÙØ±Ù…Øª MongoDB
                documents = []
                for summary in summaries:
                    doc = {
                        '_id': f"{summary[1]}_{summary[2]}",  # date_symbol
                        'date': summary[1],
                        'symbol': summary[2],
                        'final_score': summary[3],
                        'recommendation': summary[4],
                        'analysis': json.loads(summary[5]),
                        'created_at': datetime.now()
                    }
                    documents.append(doc)
                
                # Ø¯Ø±Ø¬ Ø¯Ø± MongoDB
                collection = db['daily_analysis']
                result = collection.insert_many(documents, ordered=False)
                
                # Ø¹Ù„Ø§Ù…Øªâ€ŒÚ¯Ø°Ø§Ø±ÛŒ Ø§Ù†ØªÙ‚Ø§Ù„ Ù…ÙˆÙÙ‚
                for summary in summaries:
                    cursor.execute('''
                        UPDATE daily_summaries SET transferred_to_mongodb = 1
                        WHERE id = ?
                    ''', (summary[0],))
                
                conn.commit()
                logger.info(f"âœ… {len(result.inserted_ids)} Ø³Ù†Ø¯ Ø¨Ù‡ MongoDB Ù…Ù†ØªÙ‚Ù„ Ø´Ø¯")
            
            # Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…ÙˆÙ‚Øª
            self._cleanup_temp_data()
            
            client.close()
            conn.close()
            
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§Ù†ØªÙ‚Ø§Ù„ Ø¨Ù‡ MongoDB: {e}")
            self._save_to_queue()
    
    def _save_to_queue(self):
        """Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± ØµÙ Ø¨Ø±Ø§ÛŒ Ø§Ù†ØªÙ‚Ø§Ù„ Ø¨Ø¹Ø¯ÛŒ"""
        conn = sqlite3.connect(self.analysis_db)
        cursor = conn.cursor()
        
        cursor.execute('''
            SELECT * FROM daily_summaries
            WHERE transferred_to_mongodb = 0
        ''')
        
        summaries = cursor.fetchall()
        
        queue_data = []
        for summary in summaries:
            queue_data.append({
                'date': summary[1],
                'symbol': summary[2],
                'final_score': summary[3],
                'recommendation': summary[4],
                'analysis': json.loads(summary[5])
            })
        
        # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± ÙØ§ÛŒÙ„ JSON
        with open(self.mongodb_queue, 'w', encoding='utf-8') as f:
            json.dump(queue_data, f, ensure_ascii=False, indent=2)
        
        logger.info(f"ğŸ’¾ {len(queue_data)} Ø±Ú©ÙˆØ±Ø¯ Ø¯Ø± ØµÙ MongoDB Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯")
        conn.close()
    
    def _cleanup_temp_data(self):
        """Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…ÙˆÙ‚Øª"""
        conn = sqlite3.connect(self.temp_db)
        cursor = conn.cursor()
        
        # Ù¾Ø§Ú© Ú©Ø±Ø¯Ù† Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø´Ø¯Ù‡ Ø¨ÛŒØ´ Ø§Ø² 1 Ø±ÙˆØ²
        cursor.execute('''
            DELETE FROM raw_data 
            WHERE processed = 1 AND 
            datetime(timestamp) < datetime('now', '-1 day')
        ''')
        
        cursor.execute('''
            DELETE FROM analysis_results
            WHERE datetime(timestamp) < datetime('now', '-1 day')
        ''')
        
        conn.commit()
        conn.close()
        
        logger.info("ğŸ§¹ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…ÙˆÙ‚Øª Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ø´Ø¯")
    
    def start_collection_cycle(self):
        """Ø´Ø±ÙˆØ¹ Ú†Ø±Ø®Ù‡ Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ùˆ ØªØ­Ù„ÛŒÙ„"""
        logger.info("ğŸš€ Ø³ÛŒØ³ØªÙ… Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø±ÙˆØ²Ø§Ù†Ù‡ ÙØ¹Ø§Ù„ Ø´Ø¯")
        
        # Ø¨Ø±Ù†Ø§Ù…Ù‡â€ŒØ±ÛŒØ²ÛŒ Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ (Ù‡Ø± 5 Ø¯Ù‚ÛŒÙ‚Ù‡)
        schedule.every(5).minutes.do(self._collect_all_markets)
        
        # Ø¨Ø±Ù†Ø§Ù…Ù‡â€ŒØ±ÛŒØ²ÛŒ ØªØ­Ù„ÛŒÙ„ (Ù‡Ø± 30 Ø¯Ù‚ÛŒÙ‚Ù‡)
        schedule.every(30).minutes.do(self._analyze_all_symbols)
        
        # Ø¨Ø±Ù†Ø§Ù…Ù‡â€ŒØ±ÛŒØ²ÛŒ Ø®Ù„Ø§ØµÙ‡ Ø±ÙˆØ²Ø§Ù†Ù‡ (Ø³Ø§Ø¹Øª 23:00)
        schedule.every().day.at("23:00").do(self.prepare_daily_summary)
        
        # Ø¨Ø±Ù†Ø§Ù…Ù‡â€ŒØ±ÛŒØ²ÛŒ Ø§Ù†ØªÙ‚Ø§Ù„ Ø¨Ù‡ MongoDB (Ø³Ø§Ø¹Øª 23:30)
        schedule.every().day.at("23:30").do(self.transfer_to_mongodb)
        
        # Ø§Ø¬Ø±Ø§ÛŒ Ø§ÙˆÙ„ÛŒÙ‡
        self._collect_all_markets()
        
        # Ø­Ù„Ù‚Ù‡ Ø§ØµÙ„ÛŒ
        while True:
            schedule.run_pending()
            time_module.sleep(60)
    
    def _collect_all_markets(self):
        """Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø§Ø² ØªÙ…Ø§Ù… Ø¨Ø§Ø²Ø§Ø±Ù‡Ø§"""
        markets = [
            ('BTC/USDT', 'crypto'),
            ('ETH/USDT', 'crypto'),
            ('AAPL', 'stock'),
            ('GOOGL', 'stock'),
            ('EUR/USD', 'forex'),
            ('GOLD', 'commodity')
        ]
        
        for symbol, market in markets:
            self.collect_market_data(symbol, market)
    
    def _analyze_all_symbols(self):
        """ØªØ­Ù„ÛŒÙ„ ØªÙ…Ø§Ù… Ø³Ù…Ø¨Ù„â€ŒÙ‡Ø§"""
        conn = sqlite3.connect(self.temp_db)
        cursor = conn.cursor()
        
        cursor.execute('SELECT DISTINCT symbol FROM raw_data WHERE processed = 0')
        symbols = cursor.fetchall()
        
        for (symbol,) in symbols:
            self.analyze_and_score(symbol)
        
        conn.close()
    
    def create_daily_persian_report(self):
        """Ø§ÛŒØ¬Ø§Ø¯ Ú¯Ø²Ø§Ø±Ø´ Ø¬Ø§Ù…Ø¹ ÙØ§Ø±Ø³ÛŒ Ø±ÙˆØ²Ø§Ù†Ù‡"""
        try:
            conn = sqlite3.connect(self.analysis_db)
            cursor = conn.cursor()
            
            # Ø¢Ù…Ø§Ø± Ú©Ù„ÛŒ Ø±ÙˆØ²
            cursor.execute('''
                SELECT COUNT(*), AVG(final_score), 
                       SUM(CASE WHEN final_score >= 80 THEN 1 ELSE 0 END) as strong_buys,
                       SUM(CASE WHEN final_score >= 65 THEN 1 ELSE 0 END) as buys,
                       SUM(CASE WHEN final_score <= 35 THEN 1 ELSE 0 END) as sells
                FROM daily_summaries 
                WHERE date = DATE('now')
            ''')
            
            stats = cursor.fetchone()
            total_symbols = stats[0] if stats[0] else 0
            avg_score = stats[1] if stats[1] else 0
            strong_buys = stats[2] if stats[2] else 0
            buys = stats[3] if stats[3] else 0
            sells = stats[4] if stats[4] else 0
            
            # Ø¨Ù‡ØªØ±ÛŒÙ† Ø¹Ù…Ù„Ú©Ø±Ø¯Ù‡Ø§
            cursor.execute('''
                SELECT symbol, final_score, recommendation 
                FROM daily_summaries 
                WHERE date = DATE('now')
                ORDER BY final_score DESC 
                LIMIT 5
            ''')
            
            top_performers = cursor.fetchall()
            
            # Ú¯Ø²Ø§Ø±Ø´ Ø¬Ø§Ù…Ø¹
            report_data = {
                'total_symbols_analyzed': total_symbols,
                'average_score': round(avg_score, 2) if avg_score else 0,
                'strong_buy_signals': strong_buys,
                'buy_signals': buys,
                'sell_signals': sells,
                'top_performers': [
                    {'symbol': row[0], 'score': row[1], 'recommendation': row[2]}
                    for row in top_performers
                ]
            }
            
            conn.close()
            
            # Ú¯Ø²Ø§Ø±Ø´ ÙØ§Ø±Ø³ÛŒ
            self.reporter.info(
                "Ú¯Ø²Ø§Ø±Ø´ Ø±ÙˆØ²Ø§Ù†Ù‡",
                f"ØªØ­Ù„ÛŒÙ„ {total_symbols} Ù†Ù…Ø§Ø¯ - Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø§Ù…ØªÛŒØ§Ø²: {avg_score:.1f} - Ø³ÛŒÚ¯Ù†Ø§Ù„ Ø®Ø±ÛŒØ¯ Ù‚ÙˆÛŒ: {strong_buys}",
                report_data
            )
            
            return report_data
            
        except Exception as e:
            self.reporter.error(
                "Ø®Ø·Ø§ Ø¯Ø± Ú¯Ø²Ø§Ø±Ø´ Ø±ÙˆØ²Ø§Ù†Ù‡",
                f"Ø®Ø·Ø§ Ø¯Ø± Ø§ÛŒØ¬Ø§Ø¯ Ú¯Ø²Ø§Ø±Ø´ Ø±ÙˆØ²Ø§Ù†Ù‡: {str(e)}"
            )
            return {}

# Ù†Ù…ÙˆÙ†Ù‡ Ø§Ø³ØªÙØ§Ø¯Ù‡
if __name__ == "__main__":
    collector = DailyDataCollectionSystem()
    
    # ØªØ³Øª Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ùˆ ØªØ­Ù„ÛŒÙ„
    collector.collect_market_data('BTC/USDT', 'crypto')
    result = collector.analyze_and_score('BTC/USDT')
    
    if result:
        print(f"\nğŸ“Š Ù†ØªÛŒØ¬Ù‡ ØªØ­Ù„ÛŒÙ„ {result['symbol']}:")
        print(f"Ø§Ù…ØªÛŒØ§Ø² Ù†Ù‡Ø§ÛŒÛŒ: {result['final_score']:.1f}")
        print(f"ØªÙˆØµÛŒÙ‡: {result['recommendation']}")
        
    # Ø¨Ø±Ø§ÛŒ Ø§Ø¬Ø±Ø§ÛŒ Ú©Ø§Ù…Ù„:
    # collector.start_collection_cycle()